{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('df_mapped_final.csv')\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(['index', 'Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whiskey_name</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>whiskey_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10th Mountain \"Colorado Clear\" Mountain Moonshine</td>\n",
       "      <td>ErikWachtmeister</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10th Mountain \"Colorado Clear\" Mountain Moonshine</td>\n",
       "      <td>buffalol20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10th Mountain \"Colorado Clear\" Mountain Moonshine</td>\n",
       "      <td>dkblattner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10th Mountain Bourbon</td>\n",
       "      <td>Andrew-Denniger</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th Mountain Bourbon</td>\n",
       "      <td>Bernie-Wing</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        whiskey_name              name  \\\n",
       "0  10th Mountain \"Colorado Clear\" Mountain Moonshine  ErikWachtmeister   \n",
       "1  10th Mountain \"Colorado Clear\" Mountain Moonshine        buffalol20   \n",
       "2  10th Mountain \"Colorado Clear\" Mountain Moonshine        dkblattner   \n",
       "3                              10th Mountain Bourbon   Andrew-Denniger   \n",
       "4                              10th Mountain Bourbon       Bernie-Wing   \n",
       "\n",
       "   rating  whiskey_id  user_id  \n",
       "0     4.0           1        1  \n",
       "1     4.0           1        2  \n",
       "2     3.0           1        3  \n",
       "3     4.0           2        4  \n",
       "4     5.0           2        5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    428472.000000\n",
       "mean          3.746347\n",
       "std           0.903495\n",
       "min           0.000000\n",
       "25%           3.000000\n",
       "50%           4.000000\n",
       "75%           4.000000\n",
       "max           5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean rating is around 3.75. The rating dataset skews left. \n",
    "df['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25e97055ba8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can see that our rating dataset is significantly skewed\n",
    "%matplotlib inline\n",
    "plt.hist(df['rating'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0.000000       30\n",
       "0.250000       58\n",
       "0.500000       89\n",
       "0.625000        2\n",
       "0.750000       43\n",
       "0.875000        1\n",
       "1.000000     7059\n",
       "1.125000        3\n",
       "1.208333        1\n",
       "1.250000       77\n",
       "1.333333        1\n",
       "1.375000        1\n",
       "1.416667        1\n",
       "1.500000      305\n",
       "1.625000        2\n",
       "1.666667        3\n",
       "1.750000      176\n",
       "1.833333        1\n",
       "1.875000        9\n",
       "1.916667        1\n",
       "2.000000    26714\n",
       "2.083333        1\n",
       "2.125000        6\n",
       "2.166667        1\n",
       "2.250000      483\n",
       "2.333333        7\n",
       "2.375000       17\n",
       "2.416667        1\n",
       "2.458333        1\n",
       "2.500000     1736\n",
       "            ...  \n",
       "4.285714        2\n",
       "4.291667        2\n",
       "4.300000        1\n",
       "4.312500        5\n",
       "4.333333       61\n",
       "4.350000        1\n",
       "4.375000      183\n",
       "4.416667       18\n",
       "4.444444        1\n",
       "4.500000     6657\n",
       "4.541667        1\n",
       "4.550000        1\n",
       "4.562500        2\n",
       "4.583333       14\n",
       "4.600000        3\n",
       "4.625000      151\n",
       "4.650000        1\n",
       "4.666667       47\n",
       "4.687500        3\n",
       "4.708333        1\n",
       "4.714286        1\n",
       "4.750000     2062\n",
       "4.800000        1\n",
       "4.812500        2\n",
       "4.833333       17\n",
       "4.850000        2\n",
       "4.875000       70\n",
       "4.916667        6\n",
       "4.937500        1\n",
       "5.000000    79977\n",
       "Name: name, Length: 122, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are values falling outside of the 0.25 intervals \n",
    "# Because we aggregate ratings of people rating the same items more than once \n",
    "df.groupby('rating')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskeys = pd.read_csv('whiskey_data_new_final_for_KNN.csv')\n",
    "whiskeys.drop('Index', axis = 1, inplace = True)\n",
    "\n",
    "whiskey_set1 = set(df['whiskey_name'])\n",
    "whiskey_set2 = set(whiskeys['whiskey_name'])\n",
    "whiskey_set = whiskey_set1 & whiskey_set2\n",
    "df = df.loc[df.whiskey_name.isin(whiskey_set)].reset_index()\n",
    "df.drop('index', axis = 1, inplace = True)\n",
    "whiskeys = whiskeys.loc[whiskeys.whiskey_name.isin(whiskey_set)].reset_index()\n",
    "whiskeys.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428472, 5)\n",
      "(2330, 28)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(whiskeys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskey_dict = dict(set([i for i in zip(df['whiskey_name'], df['whiskey_id'])]))\n",
    "user_dict = dict(set([i for i in zip(df['name'], df['user_id'])]))\n",
    "whiskeys = whiskeys.assign(whiskey_id=whiskeys['whiskey_name'].map(whiskey_dict))\n",
    "whiskeys.whiskey_id = whiskeys.whiskey_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the dictionary for prediction task below\n",
    "whiskey_dict = dict(set([i for i in zip(df['whiskey_id'], df['whiskey_name'])]))\n",
    "user_dict = dict(set([i for i in zip(df['user_id'], df['name'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Collaborative Filtering Recommendation Systems with Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp\n",
    "from surprise import SVD\n",
    "from surprise import NMF\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21424, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a subset of the dataset (5%) due to computational limitations\n",
    "df2 = df.sample(frac=0.05, random_state = 1)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 KNN USER-BASED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the Reader()\n",
    "df2 = df2[['user_id', 'whiskey_id', 'rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we use KNNWithMeans with a pearson_baseline\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(df2, reader)\n",
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x2b0b717c940>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "algo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9764748435198278\n",
      "{'k': 40, 'sim_options': {'name': 'msd', 'min_support': 1, 'user_based': True}}\n",
      "{'rmse': {'k': 40, 'sim_options': {'name': 'msd', 'min_support': 1, 'user_based': True}}, 'mae': {'k': 10, 'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': True}}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection.search import GridSearchCV\n",
    "param_grid = {'k': [10, 20, 30, 40, 50], # k: The (max) number of neighbors to take into account for aggregation\n",
    "              'sim_options': {'name': ['msd', 'cosine', 'pearson', 'pearson_baseline'],\n",
    "                              'min_support': [1, 2, 3, 4, 5], # The minimum number of common items\n",
    "                              'user_based': [True]}}\n",
    "\n",
    "gs_knn = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs = -1)\n",
    "gs_knn.fit(data) # data here is basically the training set\n",
    "# best RMSE score\n",
    "print(gs_knn.best_score['rmse'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_knn.best_params['rmse'])\n",
    "print(gs_knn.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    1.0087  0.9779  0.9853  0.9498  0.9651  0.9864  0.9807  0.9731  0.9673  0.9834  0.9778  0.0148  \n",
      "MAE (testset)     0.7836  0.7506  0.7602  0.7377  0.7463  0.7629  0.7517  0.7551  0.7367  0.7621  0.7547  0.0130  \n",
      "Fit time          4.88    4.80    5.76    4.85    5.91    4.92    5.77    4.84    5.71    4.86    5.23    0.46    \n",
      "Test time         0.10    0.08    0.09    0.08    0.08    0.09    0.08    0.09    0.09    0.08    0.09    0.00    \n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection.validation import cross_validate\n",
    "cv = cross_validate(KNNWithMeans(k = 40, sim_options={'name': 'msd', 'min_support': 1, 'user_based': True}),\n",
    "               data, measures=[u'rmse', u'mae'], cv=10,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(algo, input_file_name):\n",
    "    from surprise import KNNWithMeans\n",
    "    from surprise import Dataset\n",
    "    from surprise import Reader\n",
    "    \n",
    "    input_ = pd.read_csv(input_file_name)\n",
    "    input_whiskey = list(input_['whiskey_id'])\n",
    "    input_rating = list(input_['rating'])\n",
    "    \n",
    "    # When somebody enters 10 ratings for 10 whiskeys\n",
    "    new_user_id = df2['user_id'].max() + 1 # create new user_id for that person\n",
    "    input_data = pd.DataFrame({'user_id': [new_user_id]*10, # create a new dataframe for that person\n",
    "                               'whiskey_id': input_whiskey,\n",
    "                               'rating': input_rating\n",
    "        \n",
    "    })\n",
    "    df3 = [df2, input_data]\n",
    "    df3 = pd.concat(df3) # concat that dataframe into the new training set\n",
    "    df3.reset_index(inplace = True)\n",
    "    df3.drop('index', axis = 1, inplace = True)\n",
    "    \n",
    "    #KNN algorithm\n",
    "    reader = Reader()\n",
    "    data = Dataset.load_from_df(df3[['user_id', 'whiskey_id', 'rating']], reader)\n",
    "    trainingSet = data.build_full_trainset()\n",
    "    # algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True}) # change algorithm for this\n",
    "    algo.fit(trainingSet)\n",
    "    \n",
    "    # Create test set\n",
    "    chosen_whiskey = list(df2['whiskey_id'])\n",
    "    pred_whiskey = list(set(chosen_whiskey) - set(input_whiskey))\n",
    "    pred_user = [new_user_id]*len(pred_whiskey)\n",
    "    pred_true_rating = [df3['rating'].mean()]*len(pred_whiskey)\n",
    "    testSet = [i for i in zip(pred_user, pred_whiskey, pred_true_rating)]\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = algo.test(testSet)\n",
    "    # Recommendations\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    top_recs = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_recs[uid].append((whiskey_dict[iid], est))\n",
    "    for uid, user_ratings in top_recs.items():\n",
    "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        top_recs[uid] = user_ratings[:10] # Recommend 10 whiskeys\n",
    "    \n",
    "    return [i[0] for i in dict(top_recs)[uid]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Knob Creek Cask Strength Straight Rye',\n",
       " 'Glenfarclas 12 Year',\n",
       " 'Oban 14 Year',\n",
       " 'Pappy Van Winkle Family Reserve 15 Year',\n",
       " 'The Macallan 18 Year Sherry Oak Cask',\n",
       " 'Willett Family Estate Bottled Rye 4 Year',\n",
       " 'Auchentoshan American Oak',\n",
       " 'Glenmorangie Astar',\n",
       " 'Nikka Miyagikyo Single Malt',\n",
       " 'The Balvenie Doublewood 12 Year']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_name = 'user_input_set.csv' \n",
    "knn_user = KNNWithMeans(k = 40, sim_options={'name': 'msd', 'min_support': 1, 'user_based': True})\n",
    "get_top_recommendations(knn_user, input_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 KNN ITEM-BASED EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.8631075049317051\n",
      "{'k': 10, 'sim_options': {'name': 'pearson_baseline', 'min_support': 4, 'user_based': False}}\n",
      "{'rmse': {'k': 10, 'sim_options': {'name': 'pearson_baseline', 'min_support': 4, 'user_based': False}}, 'mae': {'k': 10, 'sim_options': {'name': 'pearson_baseline', 'min_support': 4, 'user_based': False}}}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'k': [10, 20, 30, 40, 50], # k: The (max) number of neighbors to take into account for aggregation\n",
    "              'sim_options': {'name': ['msd', 'cosine', 'pearson', 'pearson_baseline'],\n",
    "                              'min_support': [1, 2, 3, 4, 5], # The minimum number of common items\n",
    "                              'user_based': [False]}}\n",
    "\n",
    "gs_knn_item = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs_knn_item.fit(data) # data here is basically the training set\n",
    "# best RMSE score\n",
    "print(gs_knn_item.best_score['rmse'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_knn_item.best_params['rmse'])\n",
    "print(gs_knn_item.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.8414  0.8666  0.8361  0.8512  0.8244  0.8635  0.8894  0.8425  0.8815  0.8675  0.8564  0.0197  \n",
      "MAE (testset)     0.6579  0.6749  0.6529  0.6553  0.6525  0.6802  0.6874  0.6653  0.6864  0.6766  0.6689  0.0131  \n",
      "Fit time          0.17    0.16    0.19    0.18    0.18    0.15    0.16    0.15    0.19    0.16    0.17    0.01    \n",
      "Test time         0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n"
     ]
    }
   ],
   "source": [
    "# Seems like item-based KNN performs better than user-based KNN\n",
    "cv_knn_item = cross_validate(KNNWithMeans(k = 10, sim_options={'name': 'pearson_baseline', 'min_support': 4, 'user_based': False}),\n",
    "               data, measures=[u'rmse', u'mae'], cv=10,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Alley 6 Rye Whiskey',\n",
       " 'Amrut Peated Indian Single Malt',\n",
       " 'Amrut Portonova Single Malt',\n",
       " 'Antiquary 12 Year',\n",
       " 'Ardbeg 17 Year',\n",
       " 'Arran 17 Year',\n",
       " 'Arran Smuggler Series The Illicit Stills Vol. 1',\n",
       " 'Auchentoshan 21 Year',\n",
       " 'Balblair 1983 1st Release ',\n",
       " 'Balblair 1990 2nd Release']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_name = 'user_input_set.csv' \n",
    "knn_item = KNNWithMeans(k = 10, sim_options={'name': 'pearson_baseline', 'min_support': 4, 'user_based': False})\n",
    "get_top_recommendations(knn_item, input_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8097618870524951\n",
      "{'n_factors': 110, 'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.15}\n",
      "{'rmse': {'n_factors': 110, 'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.15}, 'mae': {'n_factors': 110, 'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.15}}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_factors': [110, 130, 160], \n",
    "              'n_epochs': [90, 110], \n",
    "              'lr_all': [0.001, 0.005],\n",
    "              'reg_all': [0.08, 0.15]}\n",
    "\n",
    "gs_svd = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs_svd.fit(data)\n",
    "\n",
    "algo = gs_svd.best_estimator['rmse']\n",
    "print(gs_svd.best_score['rmse'])\n",
    "print(gs_svd.best_params['rmse'])\n",
    "print(gs_svd.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.8188  0.8093  0.8188  0.7943  0.8329  0.7656  0.7997  0.8007  0.7986  0.8145  0.8053  0.0174  \n",
      "MAE (testset)     0.6213  0.6259  0.6331  0.6136  0.6482  0.5920  0.6239  0.6220  0.6202  0.6279  0.6228  0.0135  \n",
      "Fit time          5.75    5.42    5.47    5.45    5.42    5.47    5.44    5.42    5.46    5.42    5.47    0.09    \n",
      "Test time         0.01    0.02    0.01    0.02    0.01    0.02    0.01    0.01    0.01    0.02    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.81875272, 0.80934371, 0.81883835, 0.79433394, 0.8328682 ,\n",
       "        0.76563959, 0.79971592, 0.8007419 , 0.79856697, 0.81453145]),\n",
       " 'test_mae': array([0.62132756, 0.62593204, 0.63312755, 0.61359546, 0.64820913,\n",
       "        0.59198066, 0.62392466, 0.6219677 , 0.62015106, 0.62794055]),\n",
       " 'fit_time': (5.748585224151611,\n",
       "  5.420328855514526,\n",
       "  5.472946882247925,\n",
       "  5.454653978347778,\n",
       "  5.416581153869629,\n",
       "  5.467586040496826,\n",
       "  5.439211130142212,\n",
       "  5.421974182128906,\n",
       "  5.460716962814331,\n",
       "  5.421677827835083),\n",
       " 'test_time': (0.014637947082519531,\n",
       "  0.015257835388183594,\n",
       "  0.014603853225708008,\n",
       "  0.015017986297607422,\n",
       "  0.014658927917480469,\n",
       "  0.015241861343383789,\n",
       "  0.014509201049804688,\n",
       "  0.014986991882324219,\n",
       "  0.014467716217041016,\n",
       "  0.015035152435302734)}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(SVD(n_factors = 110, n_epochs = 90, lr_all = 0.005, reg_all = 0.15),\n",
    "               data, measures=[u'rmse', u'mae'], cv=10,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George T. Stagg Bourbon (Fall 2017)',\n",
       " 'Kavalan Solist Vinho Barrique Single Cask Strength ',\n",
       " \"Parker's Heritage Promise of Hope\",\n",
       " 'Colonel E.H. Taylor, Jr. Four Grain Bottled-in-Bond',\n",
       " 'Laphroaig 32 Year ',\n",
       " 'Pappy Van Winkle 20 Year',\n",
       " 'William Larue Weller Bourbon (Fall 2015)',\n",
       " 'The Macallan Rare Cask ',\n",
       " 'Lagavulin Distillers Edition',\n",
       " 'Four Roses Limited Edition Small Batch Bourbon (2015)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_name = 'user_input_set.csv'\n",
    "svd = SVD(n_factors = 110, n_epochs = 90, lr_all = 0.005, reg_all = 0.15)\n",
    "get_top_recommendations(svd, input_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 SVD++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8176061520033605\n",
      "{'n_factors': 110, 'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.15}\n",
      "{'rmse': {'n_factors': 110, 'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.15}, 'mae': {'n_factors': 110, 'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.15}}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_factors': [110, 130, 160], \n",
    "              'n_epochs': [90, 110], \n",
    "              'lr_all': [0.001, 0.005],\n",
    "              'reg_all': [0.08, 0.15]}\n",
    "\n",
    "gs_svdpp = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs_svdpp.fit(data)\n",
    "\n",
    "algo = gs_svdpp.best_estimator['rmse']\n",
    "print(gs_svdpp.best_score['rmse'])\n",
    "print(gs_svdpp.best_params['rmse'])\n",
    "print(gs_svdpp.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.8291  0.8124  0.8133  0.8022  0.7926  0.8262  0.7970  0.8161  0.7982  0.8259  0.8113  0.0126  \n",
      "MAE (testset)     0.6398  0.6339  0.6329  0.6227  0.6189  0.6387  0.6159  0.6410  0.6136  0.6377  0.6295  0.0101  \n",
      "Fit time          20.90   20.86   20.98   21.01   20.83   21.19   21.02   21.05   20.94   21.08   20.99   0.10    \n",
      "Test time         0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.82906655, 0.81242193, 0.81331612, 0.80219032, 0.79264384,\n",
       "        0.82624096, 0.79702988, 0.81612359, 0.79819815, 0.82587159]),\n",
       " 'test_mae': array([0.63977273, 0.63391031, 0.63285973, 0.62269371, 0.61893343,\n",
       "        0.63865548, 0.61590692, 0.64097867, 0.61362728, 0.63771287]),\n",
       " 'fit_time': (20.899518966674805,\n",
       "  20.860366106033325,\n",
       "  20.983689785003662,\n",
       "  21.013669967651367,\n",
       "  20.827924013137817,\n",
       "  21.1859610080719,\n",
       "  21.018309116363525,\n",
       "  21.048537731170654,\n",
       "  20.93875789642334,\n",
       "  21.080537796020508),\n",
       " 'test_time': (0.025869131088256836,\n",
       "  0.029565811157226562,\n",
       "  0.026173830032348633,\n",
       "  0.025570154190063477,\n",
       "  0.025906801223754883,\n",
       "  0.02565598487854004,\n",
       "  0.025543928146362305,\n",
       "  0.02553272247314453,\n",
       "  0.025207996368408203,\n",
       "  0.03000807762145996)}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(SVDpp(n_factors = 110, n_epochs = 90, lr_all = 0.005, reg_all = 0.15),\n",
    "               data, measures=[u'rmse', u'mae'], cv=10,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George T. Stagg Bourbon (Fall 2017)',\n",
       " 'Pappy Van Winkle 23 Year',\n",
       " 'Pappy Van Winkle 20 Year',\n",
       " 'The Macallan Rare Cask ',\n",
       " 'Bruichladdich Black Art 1990 04.1 Edition',\n",
       " 'Lagavulin Distillers Edition',\n",
       " \"Booker's Rye Whiskey Big Time Batch (2016 Release)\",\n",
       " \"Parker's Heritage Promise of Hope\",\n",
       " 'Four Roses Limited Edition Small Batch Bourbon (2015)',\n",
       " 'Laphroaig 15 Year 200th Anniversary ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_name = 'user_input_set.csv'\n",
    "svdpp = SVDpp(n_factors = 110, n_epochs = 90, lr_all = 0.005, reg_all = 0.15)\n",
    "get_top_recommendations(svdpp, input_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943679134840858\n",
      "{'n_factors': 160, 'n_epochs': 90}\n",
      "{'rmse': {'n_factors': 160, 'n_epochs': 90}, 'mae': {'n_factors': 160, 'n_epochs': 90}}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_factors': [110, 130, 160], \n",
    "              'n_epochs': [90, 110, 130]}\n",
    "\n",
    "gs_nmf = GridSearchCV(NMF, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs_nmf.fit(data)\n",
    "\n",
    "algo = gs_nmf.best_estimator['rmse']\n",
    "print(gs_nmf.best_score['rmse'])\n",
    "print(gs_nmf.best_params['rmse'])\n",
    "print(gs_nmf.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.9444  0.9301  0.9382  0.9545  0.9572  0.9348  0.9440  0.9379  0.9170  0.9334  0.9392  0.0111  \n",
      "MAE (testset)     0.7432  0.7198  0.7338  0.7459  0.7597  0.7395  0.7357  0.7352  0.7186  0.7240  0.7355  0.0120  \n",
      "Fit time          21.48   21.69   21.38   21.23   21.26   22.59   22.32   22.60   22.65   21.59   21.88   0.56    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.02    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.9444436 , 0.93008308, 0.93817473, 0.9545112 , 0.95721827,\n",
       "        0.93484447, 0.94401191, 0.9378801 , 0.91703678, 0.93335423]),\n",
       " 'test_mae': array([0.74324341, 0.71982326, 0.73377065, 0.74586306, 0.75972532,\n",
       "        0.73946708, 0.73566034, 0.73524214, 0.71861763, 0.72395006]),\n",
       " 'fit_time': (21.484656810760498,\n",
       "  21.689722061157227,\n",
       "  21.37691307067871,\n",
       "  21.234088897705078,\n",
       "  21.259886264801025,\n",
       "  22.59340476989746,\n",
       "  22.318750143051147,\n",
       "  22.602141857147217,\n",
       "  22.646140813827515,\n",
       "  21.593103885650635),\n",
       " 'test_time': (0.014259099960327148,\n",
       "  0.013804912567138672,\n",
       "  0.01353907585144043,\n",
       "  0.014602184295654297,\n",
       "  0.013637781143188477,\n",
       "  0.014734983444213867,\n",
       "  0.014111042022705078,\n",
       "  0.015149116516113281,\n",
       "  0.01465296745300293,\n",
       "  0.014628171920776367)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(NMF(n_factors = 160, n_epochs = 90),\n",
    "               data, measures=[u'rmse', u'mae'], cv=10,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2eeb047aba1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'user_input_set.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_factors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_top_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-dd318c553f13>\u001b[0m in \u001b[0;36mget_top_recommendations\u001b[1;34m(algo, input_file_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtrainingSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_full_trainset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True}) # change algorithm for this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Create test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.NMF.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.NMF.sgd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division"
     ]
    }
   ],
   "source": [
    "input_file_name = 'user_input_set.csv' \n",
    "nmf = NMF(n_factors = 160, n_epochs = 90)\n",
    "get_top_recommendations(nmf, input_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 CHOOSING A MODEL FOR TESTING: SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASELINE TEST: TRUE RATINGS = MEAN RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based Model : Test Set\n",
      "RMSE: 0.4110\n",
      "0.4109923107204235\n",
      "MAE:  0.3254\n",
      "0.3254180308458317\n"
     ]
    }
   ],
   "source": [
    "# build_anti_testset(): The ratings are all the ratings that are not in the trainset \n",
    "# i.e. all the ratings r_ui where the user u is known, the item i is known, but the rating r_ui is not in the trainset. \n",
    "# As r_ui is unknown, it is either replaced by the fill value or assumed to be equal to the mean of all ratings global_mean.\n",
    "# In this case, the r_ui for the testSet is the global mean\n",
    "testSet = trainingSet.build_anti_testset()\n",
    "algo = gs_svd.best_estimator['rmse']\n",
    "algo.fit(trainingSet)\n",
    "predictions = algo.test(testSet)\n",
    "print(\"User-based Model : Test Set\")\n",
    "print(accuracy.rmse(predictions, verbose=True))\n",
    "print(accuracy.mae(predictions, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REAL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a real test set\n",
    "df_frac = df[['user_id', 'whiskey_id', 'rating']]\n",
    "df2_users = list(df2['user_id'].unique())\n",
    "df2_whiskeys = list(df2['whiskey_id'].unique())\n",
    "df_frac = df_frac[~df_frac.isin(df2).all(1)]\n",
    "df_test_full = df_frac[(df_frac['user_id'].isin(df2_users)) | (df_frac['whiskey_id'].isin(df2_whiskeys))]\n",
    "df_test = df_test_full.sample(frac=0.05, random_state = 1)\n",
    "testSet = [i for i in zip(df_test['user_id'], df_test['whiskey_id'], df_test['rating'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based Model : Test Set\n",
      "RMSE: 0.7993\n",
      "0.7993262784186548\n",
      "MAE:  0.6193\n",
      "0.619328038618325\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors = 110, n_epochs = 90, lr_all = 0.005, reg_all = 0.15)\n",
    "algo.fit(trainingSet)\n",
    "predictions = algo.test(testSet)\n",
    "print(\"User-based Model : Test Set\")\n",
    "print(accuracy.rmse(predictions, verbose=True))\n",
    "print(accuracy.mae(predictions, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rating matrix\n",
    "ratings = df2.pivot(index = 'user_id', columns ='whiskey_id', values = 'rating').fillna(0)\n",
    "r_mat = ratings.as_matrix()\n",
    "r_mean = np.mean(r_mat, axis = 1)\n",
    "demeaned_mat = r_mat - r_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>whiskey_id</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>2310</th>\n",
       "      <th>2313</th>\n",
       "      <th>2314</th>\n",
       "      <th>2316</th>\n",
       "      <th>2317</th>\n",
       "      <th>2318</th>\n",
       "      <th>2319</th>\n",
       "      <th>2321</th>\n",
       "      <th>2323</th>\n",
       "      <th>2324</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60714</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60719</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60733</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60810</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60846</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60882</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60892</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60894</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60902</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60904</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60928</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60940</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60961</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61050</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61069</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61081</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13889 rows  1571 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "whiskey_id  2     3     6     7     9     10    11    12    15    17    ...   \\\n",
       "user_id                                                                 ...    \n",
       "1            0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "3            0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "5            0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "6            0.0  4.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "9            0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "12           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "14           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "18           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "19           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "24           3.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "26           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "27           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "28           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "32           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "34           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "36           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "38           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "39           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "40           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "41           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "42           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "44           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "45           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "47           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "48           0.0  4.75   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "49           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "50           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "52           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "54           0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "55           0.0  2.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    \n",
       "60673        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60678        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60714        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60719        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60733        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60756        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60757        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60779        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60802        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60810        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60846        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60870        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60882        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60892        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60894        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60902        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60904        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60928        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60940        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60961        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "60993        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61050        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61069        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61071        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61074        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61081        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61120        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61121        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61129        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "61142        0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "\n",
       "whiskey_id  2310  2313  2314  2316  2317  2318  2319  2321  2323  2324  \n",
       "user_id                                                                 \n",
       "1           0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3           0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5           0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6           0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "9           0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "12          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "14          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "18          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "19          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "24          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "26          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "27          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "28          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "32          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "34          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "36          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "38          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "39          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "40          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "41          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "42          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "44          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "45          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "47          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "48          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "49          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "50          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "52          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "54          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "55          0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "60673       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60678       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60714       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60719       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60733       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60756       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60757       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60779       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60802       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60810       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60846       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60870       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60882       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60892       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60894       0.00   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60902       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60904       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60928       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60940       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60961       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "60993       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61050       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61069       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61071       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61074       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61081       0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61120       3.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61121       3.75   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61129       0.00   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "61142       0.00   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[13889 rows x 1571 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998496443440265"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = df.user_id.unique().shape[0]\n",
    "num_whiskeys = df.whiskey_id.unique().shape[0]\n",
    "sparsity = 1 - len(df2)/(num_users * num_whiskeys)\n",
    "sparsity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the largest k singular values/vectors for a sparse matrix.\n",
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(demeaned_mat, k = 50)\n",
    "sigma = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.dot(np.dot(U, sigma), Vt) + r_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00458677,  0.00458442,  0.00341453, ...,  0.00520884,\n",
       "         0.00431776,  0.00437345],\n",
       "       [-0.0007035 , -0.00076728, -0.00116635, ..., -0.00078229,\n",
       "        -0.00088239, -0.000688  ],\n",
       "       [ 0.00289481,  0.00289235,  0.00341308, ...,  0.00286814,\n",
       "         0.00283919,  0.00289296],\n",
       "       ...,\n",
       "       [ 0.00255834,  0.00256422,  0.00281435, ...,  0.00254484,\n",
       "         0.00254277,  0.0025617 ],\n",
       "       [ 0.00063195,  0.00063259,  0.00076366, ...,  0.00062986,\n",
       "         0.0006211 ,  0.00062995],\n",
       "       [ 0.00189584,  0.00189777,  0.00229097, ...,  0.00188958,\n",
       "         0.00186331,  0.00188986]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(all_predictions, columns = ratings.columns)\n",
    "preds.reset_index(inplace = True)\n",
    "preds.rename(columns={'index':'user_id'}, inplace=True)\n",
    "preds['user_id'] = ratings.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS FOR USERS ALREADY IN THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskeys_short = whiskeys[['whiskey_id', 'whiskey_name', 'type', 'origin', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_whiskeys(preds, user_id, whiskeys, rating_df, n):\n",
    "    \n",
    "    sorted_user_predictions = preds[preds['user_id'] == user_id].squeeze().sort_values(ascending = False)\n",
    "    user_row = int(preds[preds['user_id'] == user_id].index.values)\n",
    "    \n",
    "    # Get the user's data and merge in the movie information.\n",
    "    user_data = (rating_df[rating_df['user_id'] == user_id].merge(whiskeys, how = 'left', on = 'whiskey_id').\n",
    "                                                           sort_values(['rating'], ascending=False))\n",
    "\n",
    "    print('User {} rated {} whiskeys before.'.format(user_dict[user_id], user_data.shape[0]))\n",
    "    print('The {} recommendations for user {} are:'.format(n, user_dict[user_id]))\n",
    "    \n",
    "    recommendations = (whiskeys[~whiskeys.whiskey_id.isin(user_data.whiskey_id)].\n",
    "         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',\n",
    "         on = 'whiskey_id').rename(columns = {user_row: 'predictions'}).\n",
    "         sort_values('predictions', ascending = False).\n",
    "         iloc[:n, :-1])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turianArmy rated 1 whiskeys before.\n",
      "The 20 recommendations for user turianArmy are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whiskey_id</th>\n",
       "      <th>whiskey_name</th>\n",
       "      <th>type</th>\n",
       "      <th>origin</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2167</td>\n",
       "      <td>W.L. Weller 12 Year</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>___heated bourbon\" is bourbon with wheat as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>497</td>\n",
       "      <td>Colonel E.H. Taylor, Jr. Small Batch Bottled i...</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>As the name indicates, this is a small batch w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>671</td>\n",
       "      <td>Eagle Rare 10 Year</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Eagle Rare Straight Bourbon is one of the flag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1956</td>\n",
       "      <td>The Balvenie Doublewood 12 Year</td>\n",
       "      <td>Single Malt</td>\n",
       "      <td>Speyside, Scotland</td>\n",
       "      <td>The DoubleWood has become such an iconic bottl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2168</td>\n",
       "      <td>W.L. Weller Antique</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>The second in the Weller line, the Weller Anti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>370</td>\n",
       "      <td>Bulleit Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>The Bulleit label, revived by Tom Bulleit, was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>755</td>\n",
       "      <td>Four Roses Single Barrel Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Four Roses Single Barrel is bottled at 50% ABV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>969</td>\n",
       "      <td>Henry McKenna 10 Year Bottled in Bond Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Made by Heaven Hill Distillery, this Henry McK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1728</td>\n",
       "      <td>Rhetoric 23 Year Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>This bourbon, released in 2017, is the fourth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2269</td>\n",
       "      <td>Woodford Reserve Straight Rye</td>\n",
       "      <td>Rye</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>As of early 2015, Woodford Reserve Rye is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1309</td>\n",
       "      <td>Laphroaig Triple Wood</td>\n",
       "      <td>Peated Single Malt</td>\n",
       "      <td>Islay, Scotland</td>\n",
       "      <td>As the name implies, this whisky is triple mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>781</td>\n",
       "      <td>George T. Stagg Bourbon (Fall 2018)</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>George T. Stagg Bourbon (Fall 2018) is an uncu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>10</td>\n",
       "      <td>1792 Single Barrel Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>This single-barrel release is the third in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2233</td>\n",
       "      <td>Wild Turkey Rare Breed 116.8</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>This batch released in spring 2017 is the late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>295</td>\n",
       "      <td>Booker's Bourbon Batch 2016-05 \"Off Your Rocker\"</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky  , USA</td>\n",
       "      <td>The fifth 2016 release from Booker's Bourbon i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1118</td>\n",
       "      <td>Jefferson's Reserve</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Jefferson's Reserve is made from four differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1560</td>\n",
       "      <td>Old Forester Classic 86 Proof</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>The Old Forester brand was introduced in 1870 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>43</td>\n",
       "      <td>Abraham Bowman Gingerbread Cocoa Finished Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>A. Smith Bowman collaborated with Hardywood Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>344</td>\n",
       "      <td>Bruichladdich Black Art 1990 04.1 Edition</td>\n",
       "      <td>Single Malt</td>\n",
       "      <td>Islay, Scotland</td>\n",
       "      <td>From Bruichladdich, comes this unpeated Islay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1515</td>\n",
       "      <td>O.K.I. Reserve Straight Bourbon 9 Year</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>New Riff calls this O.K.I. because the whiskey...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     whiskey_id                                       whiskey_name  \\\n",
       "273        2167                                W.L. Weller 12 Year   \n",
       "699         497  Colonel E.H. Taylor, Jr. Small Batch Bottled i...   \n",
       "540         671                                 Eagle Rare 10 Year   \n",
       "1227       1956                    The Balvenie Doublewood 12 Year   \n",
       "405        2168                                W.L. Weller Antique   \n",
       "1393        370                                    Bulleit Bourbon   \n",
       "728         755                   Four Roses Single Barrel Bourbon   \n",
       "510         969      Henry McKenna 10 Year Bottled in Bond Bourbon   \n",
       "1419       1728                           Rhetoric 23 Year Bourbon   \n",
       "177        2269                      Woodford Reserve Straight Rye   \n",
       "1044       1309                              Laphroaig Triple Wood   \n",
       "204         781                George T. Stagg Bourbon (Fall 2018)   \n",
       "608          10                         1792 Single Barrel Bourbon   \n",
       "227        2233                       Wild Turkey Rare Breed 116.8   \n",
       "234         295   Booker's Bourbon Batch 2016-05 \"Off Your Rocker\"   \n",
       "1680       1118                                Jefferson's Reserve   \n",
       "1523       1560                      Old Forester Classic 86 Proof   \n",
       "585          43  Abraham Bowman Gingerbread Cocoa Finished Bourbon   \n",
       "103         344          Bruichladdich Black Art 1990 04.1 Edition   \n",
       "1138       1515             O.K.I. Reserve Straight Bourbon 9 Year   \n",
       "\n",
       "                    type              origin  \\\n",
       "273              Bourbon       Kentucky, USA   \n",
       "699              Bourbon       Kentucky, USA   \n",
       "540              Bourbon       Kentucky, USA   \n",
       "1227         Single Malt  Speyside, Scotland   \n",
       "405              Bourbon       Kentucky, USA   \n",
       "1393             Bourbon       Kentucky, USA   \n",
       "728              Bourbon       Kentucky, USA   \n",
       "510              Bourbon       Kentucky, USA   \n",
       "1419             Bourbon       Kentucky, USA   \n",
       "177                  Rye       Kentucky, USA   \n",
       "1044  Peated Single Malt     Islay, Scotland   \n",
       "204              Bourbon       Kentucky, USA   \n",
       "608              Bourbon       Kentucky, USA   \n",
       "227              Bourbon       Kentucky, USA   \n",
       "234              Bourbon     Kentucky  , USA   \n",
       "1680             Bourbon       Kentucky, USA   \n",
       "1523             Bourbon       Kentucky, USA   \n",
       "585              Bourbon       Virginia, USA   \n",
       "103          Single Malt     Islay, Scotland   \n",
       "1138             Bourbon            Indiana    \n",
       "\n",
       "                                            description  \n",
       "273   ___heated bourbon\" is bourbon with wheat as t...  \n",
       "699   As the name indicates, this is a small batch w...  \n",
       "540   Eagle Rare Straight Bourbon is one of the flag...  \n",
       "1227  The DoubleWood has become such an iconic bottl...  \n",
       "405   The second in the Weller line, the Weller Anti...  \n",
       "1393  The Bulleit label, revived by Tom Bulleit, was...  \n",
       "728   Four Roses Single Barrel is bottled at 50% ABV...  \n",
       "510   Made by Heaven Hill Distillery, this Henry McK...  \n",
       "1419  This bourbon, released in 2017, is the fourth ...  \n",
       "177   As of early 2015, Woodford Reserve Rye is the ...  \n",
       "1044  As the name implies, this whisky is triple mat...  \n",
       "204   George T. Stagg Bourbon (Fall 2018) is an uncu...  \n",
       "608   This single-barrel release is the third in the...  \n",
       "227   This batch released in spring 2017 is the late...  \n",
       "234   The fifth 2016 release from Booker's Bourbon i...  \n",
       "1680  Jefferson's Reserve is made from four differen...  \n",
       "1523  The Old Forester brand was introduced in 1870 ...  \n",
       "585   A. Smith Bowman collaborated with Hardywood Pa...  \n",
       "103   From Bruichladdich, comes this unpeated Islay ...  \n",
       "1138  New Riff calls this O.K.I. because the whiskey...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_whiskeys(preds, 25123, whiskeys_short, df2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS FOR USERS NOT YET IN THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = pd.read_csv('user_input_set.csv')\n",
    "input_whiskey = list(input_['whiskey_id'])\n",
    "input_rating = list(input_['rating'])\n",
    "    \n",
    "# When somebody enters 10 ratings for 10 whiskeys\n",
    "new_user_id = df['user_id'].max() + 1 # create new user_id for that person\n",
    "user_dict[new_user_id] = 'New User'\n",
    "input_data = pd.DataFrame({'user_id': [new_user_id]*10, # create a new dataframe for that person\n",
    "                               'whiskey_id': input_whiskey,\n",
    "                               'rating': input_rating})\n",
    "df3 = [df2, input_data]\n",
    "df3 = pd.concat(df3) # concat that dataframe into the new training set\n",
    "df3.reset_index(inplace = True)\n",
    "df3.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User New User rated 10 whiskeys before.\n",
      "The 20 recommendations for user New User are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whiskey_id</th>\n",
       "      <th>whiskey_name</th>\n",
       "      <th>type</th>\n",
       "      <th>origin</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>288</td>\n",
       "      <td>Booker's Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Part of Jim Beam's \"Small Batch Collection\", t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>857</td>\n",
       "      <td>Glenfiddich 15 Year Solera Reserve</td>\n",
       "      <td>Single Malt</td>\n",
       "      <td>Speyside, Scotland</td>\n",
       "      <td>The Solera Reserve expression from Glenfiddich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1163</td>\n",
       "      <td>Johnnie Walker Green Label 15 Year</td>\n",
       "      <td>Peated Blended Malt</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>The Green Label from Johnnie Walker is a blend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2034</td>\n",
       "      <td>The Macallan 18 Year Sherry Oak Cask</td>\n",
       "      <td>Single Malt</td>\n",
       "      <td>Highlands, Scotland</td>\n",
       "      <td>For many, this is the benchmark for luxury in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>413</td>\n",
       "      <td>Caol Ila 12 Year</td>\n",
       "      <td>Peated Single Malt</td>\n",
       "      <td>Islay, Scotland</td>\n",
       "      <td>Caol Ila, pronounced as ___ull Ee-la__ is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1557</td>\n",
       "      <td>Old Forester Birthday Bourbon 2016</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>The 2016 Old Forester Birthday Bourbon is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2168</td>\n",
       "      <td>W.L. Weller Antique</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>The second in the Weller line, the Weller Anti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>756</td>\n",
       "      <td>Four Roses Small Batch Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Four Roses Small Batch is a straight bourbon t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1767</td>\n",
       "      <td>Russell's Reserve Single Barrel Bourbon</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Russell's Reserve Single Barrel Kentucky Strai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2286</td>\n",
       "      <td>Yamazaki 18 Year</td>\n",
       "      <td>Single Malt</td>\n",
       "      <td>Honshu, Japan</td>\n",
       "      <td>There is an art to blending the whiskies here....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1101</td>\n",
       "      <td>Jameson Black Barrel</td>\n",
       "      <td>Blended</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Jameson Black Barrel is a whiskey comprised of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1778</td>\n",
       "      <td>Sazerac Straight Rye</td>\n",
       "      <td>Rye</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Named after the Sazerac Coffee House on Royal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>311</td>\n",
       "      <td>Bowmore 12 Year</td>\n",
       "      <td>Peated Single Malt</td>\n",
       "      <td>Islay, Scotland</td>\n",
       "      <td>This dram is a fine example of the different e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1938</td>\n",
       "      <td>Teeling Small Batch Irish Whiskey</td>\n",
       "      <td>Blended</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>After its initial aging in oak barrels, Teelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>1449</td>\n",
       "      <td>Monkey Shoulder</td>\n",
       "      <td>Blended Malt</td>\n",
       "      <td>Speyside, Scotland</td>\n",
       "      <td>The name Monkey Shoulder originates from an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>515</td>\n",
       "      <td>Compass Box Peat Monster</td>\n",
       "      <td>Peated Blended Malt</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Compass Box Peat Monster is a blended malt whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1481</td>\n",
       "      <td>Nikka Coffey Grain Whisky</td>\n",
       "      <td>Single Grain</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Grain whiskies are the base for most blended w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1089</td>\n",
       "      <td>Jack Daniel's Single Barrel Select</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Tennessee, USA</td>\n",
       "      <td>First introduced in 1997, Single Barrel Select...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>1104</td>\n",
       "      <td>Jameson Caskmates IPA Edition</td>\n",
       "      <td>Blended</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>This IPA Caskmates is the second edition of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>1130</td>\n",
       "      <td>Jim Beam Original</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>Also known as Jim Beam's White Label, Jim Beam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     whiskey_id                             whiskey_name                 type  \\\n",
       "1038        288                         Booker's Bourbon              Bourbon   \n",
       "1375        857       Glenfiddich 15 Year Solera Reserve          Single Malt   \n",
       "118        1163       Johnnie Walker Green Label 15 Year  Peated Blended Malt   \n",
       "698        2034     The Macallan 18 Year Sherry Oak Cask          Single Malt   \n",
       "1231        413                        Caol Ila 12 Year    Peated Single Malt   \n",
       "142        1557       Old Forester Birthday Bourbon 2016              Bourbon   \n",
       "400        2168                      W.L. Weller Antique              Bourbon   \n",
       "412         756           Four Roses Small Batch Bourbon              Bourbon   \n",
       "102        1767  Russell's Reserve Single Barrel Bourbon              Bourbon   \n",
       "28         2286                         Yamazaki 18 Year          Single Malt   \n",
       "1663       1101                     Jameson Black Barrel              Blended   \n",
       "530        1778                     Sazerac Straight Rye                  Rye   \n",
       "532         311                          Bowmore 12 Year   Peated Single Malt   \n",
       "829        1938        Teeling Small Batch Irish Whiskey              Blended   \n",
       "1373       1449                          Monkey Shoulder         Blended Malt   \n",
       "856         515                 Compass Box Peat Monster  Peated Blended Malt   \n",
       "517        1481                Nikka Coffey Grain Whisky         Single Grain   \n",
       "847        1089       Jack Daniel's Single Barrel Select            Tennessee   \n",
       "1702       1104            Jameson Caskmates IPA Edition              Blended   \n",
       "2132       1130                        Jim Beam Original              Bourbon   \n",
       "\n",
       "                   origin                                        description  \n",
       "1038        Kentucky, USA  Part of Jim Beam's \"Small Batch Collection\", t...  \n",
       "1375   Speyside, Scotland  The Solera Reserve expression from Glenfiddich...  \n",
       "118              Scotland  The Green Label from Johnnie Walker is a blend...  \n",
       "698   Highlands, Scotland  For many, this is the benchmark for luxury in ...  \n",
       "1231      Islay, Scotland  Caol Ila, pronounced as ___ull Ee-la__ is a ...  \n",
       "142         Kentucky, USA  The 2016 Old Forester Birthday Bourbon is the ...  \n",
       "400         Kentucky, USA  The second in the Weller line, the Weller Anti...  \n",
       "412         Kentucky, USA  Four Roses Small Batch is a straight bourbon t...  \n",
       "102         Kentucky, USA  Russell's Reserve Single Barrel Kentucky Strai...  \n",
       "28          Honshu, Japan  There is an art to blending the whiskies here....  \n",
       "1663              Ireland  Jameson Black Barrel is a whiskey comprised of...  \n",
       "530         Kentucky, USA  Named after the Sazerac Coffee House on Royal ...  \n",
       "532       Islay, Scotland  This dram is a fine example of the different e...  \n",
       "829               Ireland  After its initial aging in oak barrels, Teelin...  \n",
       "1373   Speyside, Scotland  The name Monkey Shoulder originates from an in...  \n",
       "856              Scotland  Compass Box Peat Monster is a blended malt whi...  \n",
       "517                 Japan  Grain whiskies are the base for most blended w...  \n",
       "847        Tennessee, USA  First introduced in 1997, Single Barrel Select...  \n",
       "1702              Ireland  This IPA Caskmates is the second edition of th...  \n",
       "2132        Kentucky, USA  Also known as Jim Beam's White Label, Jim Beam...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = df3.pivot(index = 'user_id', columns ='whiskey_id', values = 'rating').fillna(0)\n",
    "r_mat = ratings.as_matrix()\n",
    "r_mean = np.mean(r_mat, axis = 1)\n",
    "demeaned_mat = r_mat - r_mean.reshape(-1, 1)\n",
    "U, sigma, Vt = svds(demeaned_mat, k = 50)\n",
    "sigma = np.diag(sigma)\n",
    "all_predictions = np.dot(np.dot(U, sigma), Vt) + r_mean.reshape(-1, 1)\n",
    "preds = pd.DataFrame(all_predictions, columns = ratings.columns)\n",
    "preds.reset_index(inplace = True)\n",
    "preds.rename(columns={'index':'user_id'}, inplace=True)\n",
    "preds['user_id'] = ratings.index\n",
    "recommend_whiskeys(preds, new_user_id, whiskeys_short, df3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
